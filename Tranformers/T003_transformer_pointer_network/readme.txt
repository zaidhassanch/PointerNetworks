Seq2Seq using Transformers on the Multi30k dataset. In this video I utilize Pytorch inbuilt Transformer modules, and have a
separate implementation for Transformers from scratch. Training this model for a while (not too long) gives a BLEU score
of ~35, and I think training for longer would give even better results.

